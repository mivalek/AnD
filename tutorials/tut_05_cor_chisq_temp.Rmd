---
title: "Tutorial 5: Measures of Association"
author: "Analysing Data"
---
 
```{r, echo=F, results='asis'}
cat("
<style>
:root {
--theme-col: 179, 142, 210;
--font-col: 67, 75, 117;
}
</style>
")
```

```{r, rsetup, include=F}
knitr::opts_chunk$set(comment=NULL, collapse=T, strip.white=F, echo=T,
    message = F, warning = F, prompt = F, comment = NA, split = F, toggle = F, fig.align = "center")
knitr::knit_hooks$set(sol = function(before, options, envir){
  if (before){
    paste0('<div class="solution">')
  } else {
    paste0('</div>')
  }
},
                     toggle = function(before, options, envir){
  if (options$toggle) {
    if (before){
      paste0('<details><summary>Solution</summary>')
    } else {
      paste0('</details>')
    }
  }
})
hook_inline = knitr::knit_hooks$get('inline')
knitr::knit_hooks$set(
  inline = function(x) {
    res = hook_inline(x)
    if (is.numeric(x)) prettyNum(format(x, scientific=FALSE), big.mark=',') else res
  })
```
 
```{r task_fun, echo=FALSE}
tsk <- s_tsk <- 1 # Task counter

task <- function(x = tsk, headings = tasks_to_headings) {
  tsk <<- x + 1
  s_tsk <<- 1
  return(paste0("\\ \n\n", ifelse(headings, "### ", "**"), "Task ", x, ifelse(headings, "\n\n", ": **")))
}

subtask <- function(x = tsk - 1, y = s_tsk, headings = tasks_to_headings) {
  s_tsk <<- y + 1
  return(paste0("\\ \n\n", ifelse(headings, "#### ", "**"), "Task ", x, ".", y, ifelse(headings, "\n\n", ": **")))
}
```
 
```{r plot_theme, include=FALSE}
library(ggplot2)
bg_col <- '#fdfdfd'
default_col <- '#434b75'
theme_col <- #b38ed2
complement_col <- colortools::complementary(theme_col, F)[2]
point_col <- paste0(default_col, '88')
 
my_theme <- cowplot::theme_cowplot() +
  theme(line = element_line(colour = default_col),
        plot.background = element_rect(fill = bg_col),
        panel.background = element_rect(fill = bg_col),
        text = element_text(colour = default_col),
        title = element_text(colour = default_col),
        axis.line = element_line(colour = default_col),
        axis.ticks = element_line(colour = default_col),
        axis.text = element_text(colour = default_col),
        axis.title = element_text(colour = default_col),
        strip.background = element_rect(fill = default_col, colour = default_col),
        strip.text = element_text(colour = bg_col)
  )
update_geom_defaults("bar", list(fill = bg_col, colour = default_col))
ggplot2::theme_set(my_theme)
```
 

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(kableExtra)
library(cowplot)
library(weights)
library(Hmisc)
library(colortools)
knitr::opts_chunk$set(echo = T, fig.height=4, fig.width=5, fig.align = "center",
                      message = F, warning = F, toggle = F, cache = T)
```

This tutorial covers how to prepare for, complete, and report correlation and chi-squared analyses in R. Before you start this tutorial, you should make sure you review the relevant lecture, as this tutorial assumes you already know what these analyses are and how to interpret the output. We will also work some more on building skills in R, particulary subsetting, reporting results using inline code, and (optionally, for the particularly keen) how to write your own functions.

# Setting Up

Just like last time, all you need for this tutorial is this file and RStudio. Remember that you can easily switch between windows with the <kbd>Alt</kbd> + <kbd>&#8633; Tab</kbd> (Windows) and <kbd>&#8984;\ Command</kbd> + <kbd>&rarrb; Tab</kbd> (Mac OS) shortcuts.

`r task()`Open your analysing_data `R` project in RStudio and open a new Markdown file. Since we will be practicing reporting using inline code, we will need Markdown later on. For the tasks, get into the habit of creating new code chunks as you go.

\ 

`r task()`Aside from loading `tidyverse`, we will also be using `Hmisc` and `kableExtra`. If you don't have any of these packages installed, do that now. **Remember that installing packages is a one-off thing** so don't put the command that does it in your script. Simply type it into the console and press <kbd>&crarr;\ Enter</kbd>. The `library()` commands should always go at the top of your script, so that your script will run correctly.

```{r, eval=F, toggle=T}
install.packages("Hmisc")
library(tidyverse)
library(Hmisc)
library(kableExtra)
```

\ 

`r task()`As usual, we will need some data to work with. Since there's so much interesting information in it, let's keep looking at the `gensex` dataset we've been using so far. Add the commands to read in the data, save it as `gensex`, and clean it [as we did in previous weeks](https://mivalek.github.io/adata/prac/prac_04_wkst.html#read-in_and_clean).

```{r, toggle = T}
gensex <- read_csv("https://mivalek.github.io/adata/gen_sex_q.csv")

# recode age and gender
gensex <- gensex %>%
  mutate(Age = recode(Age, "18 years" = "18", "19 years old" = "19"),
         Age = as.numeric(Age),
         Gender = factor(Gender))

# count how many cases you're about to remove
age_removed <- gensex %>% filter(Age > 99) %>% nrow()

# count how many you're about to remove
all_missing <- gensex %>% filter(rowSums(is.na(gensex)) > 10) %>% nrow()

# remove them
gensex <- gensex %>% filter(Age < 100 & rowSums(is.na(gensex)) < 11)
```

\ 

`r subtask()`If, like me, you are getting tired of having to clean the `gensex` dataset every time you want to use it, you can save the cleaned dataset so you can easily use it again. Once you have checked and cleaned the dataset, have a look at `?write_csv` and try saving the dataset to the `data` folder in your `analysing_data` project folder.

```{r, eval = F, toggle = T}
# Using here::here(), from last term
write_csv(gensex, here::here("/data/gensex_clean.csv"))
```

\ 

# Using `$`

Before we get started, we're going to have a look at an extremely useful operator in R, namely the "dollar sign" `$`. Essentially, we use `$` to get particular variables out of tibbles, dataframes, or lists. This is called "subsetting". For example, you can read `object_name$variable_name` as "Look in `object_name` and get out `variable_name`. The following code looks in `gensex` and gets out the variable `Age`, then prints out the first few rows:

```{r}
gensex$Age %>% 
  head()
```

This might sound familiar, since we've done something like this before using `pull()`. When we were doing our data inspection and cleaning previously, we've also read `object_name %>% pull(variable_name)` as "take `object_name` and get out `variable_name`. Sure enough, we can see that the following familiar code does exactly the same thing as the one using `$` above:

```{r}
gensex %>% 
  pull(Age) %>% 
  head()
```

So, why would we use `$` when we have `pull()`, or vice versa?

On the one hand, using `pull()` has worked great for us so far. It makes the code more transparent and easier to read, because each line does only one thing. It's also more obvious what `pull()` does based on its name (i.e. pulls out a variable), whereas `$` isn't intuitive. 

However, `pull()` is part of the Tidyverse, and - this is the important part - **will only work with tibbles**, and only when `tidyverse` is loaded. We've only worked with tibbles so far, so that's not been a problem, but today we'll be working with non-tibble objects from which we will want to subset some values. The essential difference is that in the examples above, `pull()` and `$` did the same thing, but this was in a particular context, namely using tibbles. Unlike `pull()`, `$` is part of base R (that is, the default way that R works) and not part of any package, so it will always work for subsetting.

If you're still a little confused by this, don't worry - we'll work more on this in a bit. For now, try a little bit of practice using `$`.

`r task()`Get out the `Gender_comfortable_1` variable from `gensex`, calculate the mean, and round to two decimal places. Do this twice, once using `pull()` and once using `$`; you should get the same result both ways.

```{r, toggle = T}
# Using pipe + pull()
gensex %>% 
  pull(Gender_comfortable_1) %>% 
  mean() %>% 
  round(2)

# Using $
gensex$Gender_comfortable_1 %>% 
  mean() %>% 
  round(2)
```

# Correlation

The first of the two analyses we will cover today is bivariate correlation. At the end of our analysis, we want to be able to report the strength and direction of the relationship between any two variables using the correlation coefficient *r*, as well as the associated *p*-value.

## Data Preparation

As usual, before beginning any analysis, we will want to take a look at our data to make sure it's clean and correct before we proceed. Since we're using our familiar `gensex` dataset that we've cleaned already, we should be pretty happy with this, but let's have a look again at these variables. The main reason is that you can generate *r*s all day easily, but if you don't know what the variables you are correlating actually mean, that doesn't do you much good!

`r task()`Create a new object, `gensex.c`, that contains all of the variables except `Duration`, `Age`, and `Gender`. Use the codebook below to check each variable, and make sure you understand how each variable was measured.

### Codebook

```{r, echo = F}
read_csv(here::here("/data/gensex_codebook.csv")) %>% 
  kable() %>% 
  kable_styling()
```

```{r, toggle = T}
gensex.c <- gensex %>% 
  select(-Gender, -Duration, -Age)
```

\ 

## Graphing

Before we jump into calculating numbers, we should get an idea of what our data look like. This will help us better understand the numbers we get from our analysis.

### Histograms

The first thing we should do is have a look at some histograms to get a sense of how people responded to these questions. 

At the moment, our dataset `gensex.c` contains `r gensex.c %>% ncol()` variables. We could create separate histograms for each one, but that's a lot of copy/pasting! Instead, let's use `facet_wrap()` to make all the histograms at once, one for each variable. To do this, we have to make a small change to our dataset using the `melt()` function in the package `reshape2`. You will likely have to install this package in the console, then load it as below. See the aside below for more information about `melt()` if you're interested, but you aren't required to know this. (If you have any trouble installing `reshape2`, just have a look at the plot below.)

`r task()`Copy the code below to your script and replace the three ellipses `...` with the correct `ggplot` functions.

```{r, eval = F}
library(reshape2)

gensex.c %>% 
  melt() %>% 
  ggplot(...(value)) +
  ...() +
  ...(~variable)
```

```{r, fig.width = 10, toggle = T}
library(reshape2)

gensex.c %>% 
  melt() %>% 
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~variable)
```

Here we can get a sense of how our data our distributed in each variable. We can see, for example, that most people said they were very comfortable with their gender identity, which gives us the huge spike in the `Gender_comfortable_1` histogram. Similarly, we can see that people tended to say that their gender identity was quite stable, and that they tend to experience romantic and sexual attraction quite strongly. On the other hand, for example, how frequently participants reported experiencing sexual and romantic attraction varied quite a bit, with many people around the middle.

<div class="why">
<summary>Aside: `melt()`</summary>

Thus far, we've been working with tidy data where each column is a variable, and each row contains observations from the same case/participant. To remind yourself of this, you can call the `gensex.c` tibble by typing its name in the console and pressing <kbd>Enter<kbd>

```{r}
gensex.c
```

The problem is that this format won't work with `facet_wrap()` the way we want it to. `The facet_wrap()` function uses a coding variable - like a factor - to group data into separate plots. So, before we can use `facet_wrap()`, we have to reshape our dataset. 
When we use `melt()`, we still have the same data, just in a different format. By default, `melt()` turns the names of our variables into a codes, stored in a new variable called `variable`. Then, the actual observations are stored in another new variable called `value`. So, what we end up with is a dataset with only two columns, one containing every value in our dataset, and another coding for which variable that value belongs to. You can see this by running the code below:

```{r}
gensex.c %>% 
  melt() %>% 
  head()
```

To check that this has come out correctly, you can see that this new version of our data has `r gensex.c %>% melt() %>% nrow()` rows, which is the same as the number of variables in our original gensex.c dataset (`r gensex.c %>% ncol()`) times the number of participants (`r gensex.c %>% nrow()`).

If you haven't understood this completely, that's fine - we will work on reshaping data more in the future. For now, all you need to know is that `melt()` lets us change the structure of our data so we can create the plot above.
</div>

## Correlation Matrices with `rcorr()`

Now that we have some idea of what's happening in our data, let's quantify these relationships with some correlations!

To get an overall look at every correlation between every variable in `gensex.c`, we can run the code below using `rcorr()` from the `Hmisc` package. Try this by copying the code below and running it. Note that before we can run `rcorr()`, we have to change our tibble into a matrix using `as.matrix()`, because the `rcorr` function requires a matrix as input. (If you don't believe me, try commenting out the `as.matrix() %>%` line!)

```{r, eval = F}
library(Hmisc)

gensex.c %>% 
  as.matrix() %>% 
  rcorr()
```

You should get several long lists of numbers in three tables. This is more information than we might really want now, so let's see if we can narrow it down a bit. 

`r task()`Save the results of the same command above as a new object called `gs.corr` and have a look at its structure.

```{r, toggle = T}
gs.corr <- gensex.c %>% 
  as.matrix() %>% 
  rcorr()

gs.corr %>% str()
```

Aha! It's our new friend, `$`! The output here tells us that the object `gs.corr` is a list that contains three objects: `r`, `n`, and `P`. We might conclude that these are the correlation coefficients, sample size, and *p*-values, respectively. We don't care so much about the sample size, and we'll come back to the *p*-value, so let's just get the `r` values for now and make it a bit easier to read.

`r task()`Use `$` to get the matrix of correlation coefficients out of `gs.corr` and save it as `gs.corr.r`. Then, turn it into a nicely formatted table rounded to two decimal places.

```{r, toggle = T}
gs.corr.r <- gs.corr$r 

gs.corr.r %>% 
  kable(col.names = c(1:10), 
# Here I've given the variables numbers so the table isn' so wide!
        digits = 2) %>% 
  kable_styling()

# Notice that gs.corr %>% pull(r) doesn't work!
```

That's a bit better. Now, we can take a look at how to read this correlation matrix.

First, notice that all of the variable names are printed out twice: first, along the left hand side from top to bottom, and along the top from left to right. To read this table, you choose one variable on the left and one variable along the top. Where they intersect, you can find the *r*-value for the correlation between them. For example, look at the first column in your output for `Gender_comfortable_1`, column 1 in the table above. (It will be harder to read the one printed out above, because I've changed the variables names to numbers so the table all fit in the tutorial.) Each value in this column is the correlation *r* between `Gender_comfortable_1` and each variable listed on the left. If we want to know the correlation between `Gender_comfortable_1` and `Gender_stability_1`, for example, we go down the list on the left until we are in the same row as `Gender_stability_1` and then read the value - in this case, 0.61.

Another thing to notice is that one of the correlations in every column is exactly 1 - a perfect positive correlation. Why might this be? 

`r task()` Find some of the 1s in the output and note which two variables produce this value, then click the below for the solution.

<details>
<summary>Solution</summary>
You will notice that the 1s form a diagonal: they occur where each variable **is correlated with itself**. So, we can ignore these perfect correlations because they are not interesting. However, they do help us navigate around this table a bit better! You may also notice that this is because this table is mirrored on the diagonal - that is, it contains all the same numbers twice, above and below the diagonal of 1s. You can test this by finding any given variable on the left, for example `Gender_fem_1`, and another on the top row, such as `Romantic_strength_1` - the value of `r` is 0.14. If you instead find `Romantic_strength_1` on the left and `Gender_fem_1` on the top, you will again find 0.14.
</details>

Next, it would be great if we could get some *p*-values as well.

`r task()`Create a nicely formatted table of *p*-values, this time rounding to three decimal places.

```{r, toggle = T}
gs.corr$P %>% 
    kable(col.names = c(1:10), 
# Here I've given the columns numbers so the table isn' so wide!
          digits = 2) %>% 
  kable_styling()
```

This table has exactly the same format as the one above, except now, each cell contains the *p* associated with the *r* from the corresponding cell on the first table. As an example, we saw before that the correlation *r* between `Romantic_strength_1` and `Gender_fem_1` was 0.14. If we look up the same variables on this table, we can see that the *p* value for that correlation is .015. Our diagonal of 1s is now replaced by a diagonal of `NA`s, since we can't calculate a *p*-value for a perfect correlation.

We now can easily investigate the correlation between any two variables in our dataset, and whether that correlation is significant. However, in the lecture we also talked about reporting degrees of freedom and CIs, which we can't get easily from this table. So, if we want to report the results of particular correlations, we should have a look at a different function, `cor.test()`.

## Pairwise Tests with `cor.test()`

Unlike `rcorr()`, `cor.test()` only tests the correlation between pairs of variables. If we want to look at lots of variables at once, we'd be better off with `rcorr()`. However, if we want more information about a particular correlation, such as easily reportable degrees of freedom, *p*-values, and confidence intervals, `cor.test()` is the better choice.

This function takes the general form `cor.test(x, y, alternative, method, ...)`. Let's have a look at what each of these mean.

* `x` and `y` are vectors of numeric data - i.e., the two variables we want to correlate
* `alternative` must be set to one of the three options `"two.sided"`, `"less"`, or  `"greater"`. This determines the type of alternative hypothesis. Because we are going to be using two-tailed tests, we will stick with `"two-sided"`.
* `method` must beset to one of the three options `"pearson"`, `"kendall"`, or `"spearman"`. Thus far, we have only been using Pearson correlations, so we'll stick with that for now.
* `...` are other options you can change; we'll stick with the defaults for now. Remember, you can always get full  information about how to use the function via `?cor.test`.

`r task()`Use `cor.test()` to calculate the correlation between `Sexual_strength_1` and `Romantic_strength_1`.

**Hint**: If you are having trouble using pipes, try `$` instead! See the box below for more details.

<details>
<summary>Aside: Why not pipes?</summary>

To run this analysis, you may have tried something like this:

```{r, eval = F}
gensex %>% 
  select(Sexual_strength_1, Romantic_strength_1) %>% 
  cor.test(alternative = "two.sided", method = "pearson")
```

This will fail to run, with the error "argument "y" is missing, with no default". What does this mean?

Take another look at the syntax of the `cor.test()` function. We can see that the first two required arguments are `x` and `y`, separated by a comma. This means that to use this function, we have to provide two separate variables, one in the first position `x` and the other in the second position, `y`.

Remember that when we use pipes, whatever you put into the pipe is passed onto the next function on the other side. You can specify where to put the piped information with a dot `.`, but if you don't, it automatically fills in the first argument in the function. That means in the code above, we select both `Sexual_strength_1` and `Romantic_strength_1` and put them into the pipe - which puts them **both** into the `x` argument of `cor.test()`. The error is telling you that `cor.test()` doesn't think it has a second variable to perform the correlation with, because there is no data provided for `y`.

Because of this, we have to provide variables separately to the `x` and `y` arguments. We can't do this easily with pipes, but we can do it very easily using subsetting with `$`.
</details>

```{r, toggle = T}
cor.test(gensex$Sexual_strength_1, gensex$Romantic_strength_1, alternative = "two.sided", method = "pearson")
```

When we run this function, the output is some reasonably easy to read information about the results of our test. We can see here that we have:

* The type of analysis we asked for (Pearson's product-moment correlation) and the variables we used
* The value of *r* under "sample estimates: cor"
* The values of *t*, degrees of freedom, and *p*
* The 95% confidence interval around *r*

`r task()`Stop and look at the values that the output has given you. Based on what you have learned from the lecture, write down what you think this result means, and how you could interpret it.

<details>
<summary>Interpretation</summary>
First, we can see that there is a significant correlation between how strongly participants experience sexual attraction, and how strongly they experience romantic attraction. This is a reasonably strong correlation, but it's not as strong as we might expect. It's also a positive correlation. This tells us that on the whole, people who experience stronger sexual attraction also tend to experience stronger romantic attraction.
</details>

`r subtask()`Create a scatterplot of these two variables to help understand the correlation. Does this change your interpretation at all?

```{r, toggle = T}
gensex %>% 
  ggplot(aes(Sexual_strength_1, Romantic_strength_1)) +
  geom_point(position = "jitter")
```

<detail>
<summary>Interpretation</summary>
We can see that for both variables, most people tended to answer on the high end of the scale - which gives us the cluster of points in the upper right hand corner. This is somewhat concerning, because not many people answered at the middle to lower ends of either scale, so our value for *r* might not really represent what's going on. We'll worry more about this next year, when we study assumptions and bias in data; for now, just notice that this looks a bit odd.
</detail>

<div class = "warn">
<title>Correlation is not causation</title>

Although we might conclude from this result that the strength of sexual attraction and the strength of romantic attraction tend to change in the same way, that **does not mean** they are causally related. Our results do not mean that if you experience weaker sexual attraction, that will cause you to also experience weaker romantic attraction, or vice versa. It should be clear from the previous statement that there's no way to establish which of these two might be the cause and which the effect in any case. What our results do suggest is that if you experience weaker sexual attraction, you are also likely to experience weaker romantic attraction (and vice versa), to a degree that is unlikely to occur if there is in fact no real relationship at all between the strength of sexual and romantic attraction.
</div>

`r subtask()`Save the output from `cor.test()` as a new object called `sex_rom_test`, so we can use it again later.

```{r, toggle = T}
sex_rom_test <- cor.test(gensex$Sexual_strength_1, gensex$Romantic_strength_1, alternative = "two.sided", method = "pearson")
```

Our reporting in the tasks above could use some numbers, which we can get out of the output of `cor.test()`. However, we'll look first at how to calculate the *&chi;*^2^ test, since we can use exactly the same method to report the results of that test as well. If you'd like to skip ahead to inline reporting, jump down to "Reporting `htest` Objects" in the Table of Contents.

# Chi-Squared

Our second test of association is the chi-squared test. Unlike *r*, we will use chi-squared on frequency data to find out whether to categorical variables are independent of each other or not.

## Data Preparation

If we'd like to keep looking at our `gensex` data, there's an immediate problem, namely - we only have one categorical variable, namely `Gender`. For the purposes of practice, though, we can create a couple more categorial variables from our gender preference variables. 

`r task()`Run the following code to create two new factor variables, `Romantic_gender_cat` and `Sexual_gender_cat`, out of the `Romantic_gender_1` and `Sexual_gender_1` variables, and ask for a summary to have a look at them. The general format of the code should look familiar to you, but see the "What For?" box for more on `ifelse()` if you're interested! Don't worry if you don't understand this code completely; you just need to understand that the new variables contain factors with three levels: "Men" for a preference for men, "Women" for a preference for women, and "None" for no preference.

```{r}
gensex <- gensex %>% 
  mutate(Romantic_gender_cat = ifelse(Romantic_gender_1 > 5, "Men", ifelse(Romantic_gender_1 < 5, "Women", "None")),
         Romantic_gender_cat = factor(Romantic_gender_cat),
         Sexual_gender_cat = ifelse(Sexual_gender_1 > 5, "Men", ifelse(Sexual_gender_1 < 5, "Women", "None")),
         Sexual_gender_cat = factor(Sexual_gender_cat))
```

<div class = "why">
<summary>Conditional Statements with `ifelse`</summary>

`ifelse()` is a base R function that might be familiar to you if you've done any other work with computers, for example with Excel. Its syntax is very simple, which we can review via `?ifelse()`: `ifelse(test, yes, no)`. This simply means that the first argument is some logical test. If the result of that test is yes (ie `TRUE`) then R should do whatever we put in the `yes` argument. If the result is no (i.e. `FALSE`), then R should instead do whatever we put into the `no` argument. Let's look at a simple example:

```{r}
weather <- "sunny"

ifelse(weather == "sunny", "go for a walk", "stay inside and watch Netflix")

```

Because the value in the first argument is `TRUE` (ie the `weather` object is equal to `"sunny"`), R printed out the `yes` response and told me to go outside. If the weather changes:

```{r}
weather <- "stormy"

ifelse(weather == "sunny", "go for a walk", "stay inside and watch Netflix")

```

R wisely advises Netflix and chill.

In the code to change our variables, above, we have nested `ifelse()` statements. Take a look at that code again:

```{r, eval = F}
ifelse(Romantic_gender_1 > 5, "Preference for Men", ifelse(Romantic_gender_1 < 5, "Preference for Women", "No Preference"))`
```

In the first `ifelse`, we asked whether the value of `Romantic_gender_1` is greater than 5 (i.e. is 6 - 9). If that's true, we want to save this as "Preference for Men". However, this still leaves the values 1 - 5, and we saw in our codebook that while values of 1 - 4 indicate preference for women, a value of 5 exactly means no preference. So, in the `no` argument of the first `ifelse`, we put in a second `ifelse` that asks if `Romantic_gender_1` was less than 5 (i.e. 1 - 4). If true, then we save this as "Preference for Women". If neither of these conditions are true - that is, the participant chose 5 - then this is recorded as "No Preference".
</div>

Before we move on, we should get some summaries of our data to help us get an idea of what's going on.

`r task()`Create two nicely formatted contingency (frequencies) tables of `Sexual_gender_cat` and `Romantic_gender_cat`, split up by `Gender`, as below.

```{r, toggle = T}
gensex %>%
  select(Gender, Sexual_gender_cat) %>% 
  group_by(Gender) %>% 
  table() %>% 
  kable(caption = "Frequencies of Sexual Gender Preference by Gender Identity") %>% 
  kable_styling()

gensex %>%
  select(Gender, Romantic_gender_cat) %>% 
  group_by(Gender) %>% 
  table() %>% 
  kable(caption = "Frequencies of Romantic Gender Preference by Gender Identity") %>% 
  kable_styling()
```

## Graphing

As above, it's always a good idea to graph your data so you can understand it clearly, as well as present it more easily. This time around, we're going to make a nicely formatted graph that we might want to put in a paper to present this information clearly.

`r task()`Create a bar graph of the romantic gender preference data.

`r subtask()` Start by creating a plot that looks like the one below.

**Hints:**
* In `aes()`, use `fill = variable_name` to split up the bars on the x-axis by that variable
* In your geom function, use `position = "dodge"` to put the bars side by side
  + You can also try leaving this out to see what happens!
* Use `labs()` to rename the labels informatively.

```{r, toggle = T}
gensex %>% 
  ggplot(aes(Romantic_gender_cat, fill = Gender)) +
  geom_bar(position = "dodge") +
  labs(x = "Romantic Preference for Genders", y = "Frequency") +
  theme_cowplot()
```
This plot gives us a clear idea of gender preference across all variables. However, for our chi-squared analysis, we're only going to focus on factors that have two levels. Next, let's create a plot that specifically represents the categories we'll use in our analysis.


`r subtask()`Filter your data before the `ggplot` command to only male and female in `Gender`, and only women and men in `Romantic_gender_cat`. Then try adding a new layer using `scale_fill_manual(values = c(...))` to change the colours of the bars. You can provide any colours you like inside `c()`; I've chosen teal and yellow using hex codes for fun, but you might want to choose something a bit more subdued for your report!

```{r, toggle = T}
gensex %>% 
  filter(Gender %in% c("Male", "Female")) %>%
  filter(Romantic_gender_cat %in% c("Men", "Women")) %>% 
  ggplot(aes(Romantic_gender_cat, fill = Gender)) +
  geom_bar(position = "dodge") +
  labs(x = "Romantic Preference for Genders", y = "Frequency") +
  scale_fill_manual(values = c("#08AA9C", "#EEC626"))
```

From this graph, we can see that female-ID people reported a much stronger romantic preference for men than for for women, whereas male-ID people showed some, but not substantial, romantic preference for women over men.

## Analysis with `chisq.test()`

Let's now have a go at producing a statistic analysis of the pattern we observed above in gender identity vs romantic preference for genders. To do this, we will use a base R function called `chisq.test()`, which is very similar in many ways to `cor.test()`, which we used above.

This function takes the general form `chisq.test(x, y = NULL, ...)`. This is a bit simpler than we saw before; there is only one required argument, `x`. The help documentation `?chisq.test` tells us that `x` can be a matrix with numbers in it. We can do this other ways, but the easiest is to create a contingency table and then feed this into `chisq.test()`.

`r task()`Create a contingency (frequency) table for `Romantic_gender_cat` grouped by `Gender` and save it as `rom_gend_tab`.

**Hint:** You will have to filter for only male/female gender, and men/women preference, as we just did above.

```{r, toggle = T}
rom_gend_tab <- gensex %>% 
  select(Gender, Romantic_gender_cat) %>% 
  filter(Gender %in% c("Male", "Female")) %>%
  filter(Romantic_gender_cat %in% c("Men", "Women")) %>% 
  table()

rom_gend_tab
```

That's looking good, except we have remaining categories for "None" and "Other", even though we filtered them from the data. We just need to tell R to drop these extra levels, since we're not using them right now.

`r subtask()`Run the code below to produce the final contingency table. Everything is the same except for a brief detour through `as.data.frame()` through `droplevels.data.frame()` to get rid of the empty categories.

```{r}
rom_gend_tab <- gensex %>% 
  select(Gender, Romantic_gender_cat) %>% 
  filter(Gender %in% c("Male", "Female")) %>%
  filter(Romantic_gender_cat %in% c("Men", "Women")) %>% 
  as.data.frame() %>% 
  droplevels.data.frame() %>% 
  table()
```

Now our data are ready to go!

`r task()` Put the contingency table into `chisq.test()` to run the analysis and save the output as `rom_pref_test`. Call that object to view the output of the test.

```{r, toggle = T}
rom_pref_test <- chisq.test(rom_gend_tab)
rom_pref_test
```

As we might have suspected from the graph, our results show that it's very unlikely that gender identity and romantic gender preference are independent from each other! Rather, we might conclude that identifying as a particular gender (male vs female) means you are likely to also romantically prefer women or men, respectively.

<div class = "warn">
<title>Association is not causation</title>

As we saw above, although we might conclude from this result that gender identity and romantic gender preference are not independent of each other, that **does not mean** they are causally related. Our results do not mean that identifying as female, for example, causes you to prefer men romantically. What they do suggest is that if you identify as female, you are also likely to prefer men romantically, to a degree that is unlikely to occur if there is in fact no real relationship at all between gender identity and romantic gender preference.
</div>

`r task()`If you would like more practice with preparing and running data for chi-squared tests, do the same again but with the `Sexual_gender_cat` variable.

\ 

# Reporting `htest` Objects

In the sections above, we ran two analyses that we would like to report, one correlation that we saved as `sex_rom_test` and one chi-squared analysis that we saved as `rom_pref_test`. To finish our analyses, we should write up the results of these tests as in a report. To do that, it would be very useful if we could extract all of the information about these tests for reporting in inline code. Luckily, R makes it very easy to do that! 

## Reporting Correlations

Let's look first at the correlation result, `sex_rom_test`.

`r task()`Call the name of the object `sex_rom_test` to see the displayed output.

```{r corr_remind, toggle = T}
sex_rom_test
```

This is the same output that we saw above when we first ran the analysis. Although this is useful for us, the analysts, to understand the result, it's not at all formatted well for reports. Luckily, there's actually a lot more stored in this object than just this text! 

`r task()`Use `class()` and `str()` to look at the class and structure of the `sex_rom_test` object.

```{r, toggle = T}
sex_rom_test %>% class()
sex_rom_test %>% str()
```

The first command tells us that this object, which contains the results from the function `cor.test()`, has the class `htest`. What does this mean? Objects of this class tend to have a specific structure, which we can see using `str()`. Now we can see that there is a lot more stored in here than it seems. If we want to get out specific values, we can simply subset them using `$`, as the output from `str()` suggests. This object contains the following useful  elements (among others):

* `statistic`: the calculated value of *t*
* `parameter`: the degrees of freedom for *t*
* `p.value`: the *p*-value
* `estimate`: the value of *r*
* `conf.int`: the values of the lower and upper bounds of the confidence intervals

`r task()`Use subsetting to extract the value of *r* from this analysis.

```{r, toggle = T}
sex_rom_test$estimate
```

That's very cool, but we can do a bit better... 

`r task()`Use subsetting to extract the value of *r* from this analysis, then round it to two decimal places.

```{r, toggle = T}
sex_rom_test$estimate %>% 
  round(2)
```

That's looking very good! Now, if I want to report the correlation coefficient for this analysis as part of my writeup, I could write:

<code><pre>Ratings of the strength of sexual and romantic attraction were correlated at *r* = &#96;r sex_rom_test$estimate %>% round(2)&#96;</pre></code>

Which would be rendered by Markdown as:

Ratings of the strength of sexual and romantic attraction were correlated at *r* = `r sex_rom_test$estimate %>% round(2)`

Once we have the basic idea, we can get almost any value of interest from this object using subsetting. The only other thing you need to know is that if subsetting gives you multiple numbers, you can get out just one of them using square brackets with a number. For example, this code: `object_name$variable_name[1]` will give you the first observation in that variable.

`r task()`Use subsetting with square brackets to get out the lower and higher bounds of the confidence intervals from `sex_rom_test`.

```{r, toggle = T}
sex_rom_test$conf.int[1]
sex_rom_test$conf.int[2]
```

`r task()`Complete the report of this analysis below, replacing the square brackets with inline code. Make sure you round all values to two decimal places, if necessary, except for *p*, which is rounded to three.

Strength of sexual attraction and strength of romantic attraction were significantly correlated, *r*([degrees of freedom]) = [value of *r*], 95% CI = [[lower bound], [upper bound]], *p* = [*p*-value].

<details>
<summary>Solution</summary>
<code><pre>
Strength of sexual attraction and strength of romantic attraction were significantly correlated, *r*(&#96;r sex_rom_test$parameter&#96;) = &#96;r sex_rom_test$estimate %>% round(2)&#96;, 95% CI = [&#96;r sex_rom_test$conf.int[1] %>% round(2)&#96;, &#96;r sex_rom_test$conf.int[2] %>% round(2)&#96;], *p* = &#96;r sex_rom_test$p.value %>% round(3)&#96;.
</pre></code>

Which should appear in Markdown as:

Strength of sexual attraction and strength of romantic attraction were significantly correlated, *r*(`r sex_rom_test$parameter`) = `r sex_rom_test$estimate %>% round(2)`, 95% CI = [`r sex_rom_test$conf.int[1] %>% round(2)`, `r sex_rom_test$conf.int[2] %>% round(2)`], *p* = `r sex_rom_test$p.value %>% round(3)`.

**Note**: The *p*-value actually isn't right here. Since *p* is so small, it only has 0s to three decimal places, but the value isn't actually 0. In this case, we'd be better off just typing "*p* < .001". Or, if we were a bit ambitious, we could [make a function to do the calculation for us](https://users.sussex.ac.uk/~jm636/tut_05_cor_chisq.html#bonus:_creating_functions)...
</details>

## Reporting Chi-Squared

Now that we've got the idea, we can do the same thing with the results from the chi-squared test.

`r task()`Have a look at the structure of the `rom_pref_test` object and compare to same command for `sex_rom_test`.

```{r, toggle = T}
rom_pref_test %>% str()
```

Here we can see the advantage of the `htest` objects - many of the elements are called the same thing, so we can get them out in the same way as we did before. As before, we can see we have the following useful elements:

* `statistic`: the calculated value of *&chi;*^2^
* `parameter`: the degrees of freedom
* `p.value`: the *p*-value
* `observed`: a table of the observed frequencies
* `expected`: a table of the expected frequencies

`r task()`Use subsetting to get a table of expected frequencies and format it nicely. Have we met the assumptions for the chi-squared test?

```{r, toggle = T}
rom_pref_test$expected %>% 
  kable(caption = "Expected Frequencies", digits = 2) %>% 
  kable_styling()

# The assumption that all expected frequencies are greater than 5 has been met - all's well!
```

`r task()`Complete the report of this analysis below, replacing the square brackets with inline code. Make sure you round all values to two decimal places, if necessary, except for *p*, which is rounded to three.

There was a significant association between gender identity and romantic gender preference, *&chi;*^2^([degrees of freedom]) = [value of chi-squared], *p* = [*p*-value].

<details>
<summary>Solution</summary>
<code><pre>
There was a significant association between gender identity and romantic gender preference, *&chi;*^2^(&#96;r rom_pref_test$parameter&#96;) = &#96;r rom_pref_test$statistic %>% round(2)&#96;, *p* = &#96;r rom_pref_test$p.value %>% round(3)&#96;.
</pre></code>

Which should appear in Markdown as:

There was a significant association between gender identity and romantic gender preference, *&chi;*^2^(`r rom_pref_test$parameter`) = `r rom_pref_test$statistic %>% round(2)`, *p* = `r rom_pref_test$p.value %>% round(3)`.

**Note**: The *p*-value isn't right here again. Since *p* is so small, it only has 0s to three decimal places, but the value isn't actually 0, just extremely tiny. In this case, we'd be better off just typing "*p* < .001". Or, if we were a bit ambitious, we could [make a function to do the calculation for us](https://users.sussex.ac.uk/~jm636/tut_05_cor_chisq.html#bonus:_creating_functions)...
</details>

\ 

<div class="SolText">
# Recap

\ 

Whew, that was a lot! If you feel a bit overwhelmed, don't worry. This tutorial is as much a reference for you in the future as it is for you to practice right now. You're welcome - and encouraged! - to keep working with this data to practice what we've learned today. In sum, we've covered:

* How to prepare and visualise data for correlation and chi-squared analyses
* How to run these analyses, read the output, and store them as `htest` objects
* How to use the subsetting operator `$` to easily report results

If you want to stop here, you're very welcome to do so. If you'd like a little extra, there's an some more at the end below to help us solve that problem with reporting *p*-values.
</div>

\ 

<div class="solText">
# Bonus: Creating Functions

If you are getting the hang of R, you might find that some functions don't work exactly the way you want them to, or you find yourself doing the same thing over and over and you'd like to make it more efficient. Wouldn't it be handy if you could just make your own function? Good news! You can do exactly that.

**NOTE:** This is not meant to be a complete tutorial on creating functions - just an **optional** preview for those who are interested. For more practice on writing functions, see the R resources on Canvas and in the reading lists. Read on if you're keen to learn more, but don't worry if you're not - you don't have to learn this.

When I'm writing these lectures and tutorials, one of the things I do a lot is report *p*-values. We saw just above that you could get the *p*-value easily out of an `htest` object and use `round(3)` to round it. However, this has some problems. First, `round()` includes the 0 before the decimal, whereas good reporting does not include this.
Second, and more importantly, I want to report *p* differently in different contexts. As a general rule, I want to report the exact value of *p* to three decimal places. However, if *p* is very small, this will result in "*p* = .000", which isn't really true; *p* isn't 0, it's just smaller than the number of decimal places we're reporting. I could report *p* to more decimal places, but honestly this isn't a good look; if *p* is that small, it doesn't really matter if it's .00001 or .0000000000001, unless you're showing off (weird flex...). Instead, if *p* is smaller than three decimal places can show, I want to report it as "*p* < .001" and move on with my life.

The best way to create a function is to write code that does what you want, and then build the function around it, so let's start by addressing those points one at a time.

First, I need a function that rounds *p* the way I want. Namely, I **always** want three decimal places, even if the last number is a 0; and I don't want the leading 0 before the decimal. After some research, I find that the `rd()` function from the `weights` package will do this. Let's try it (remember you will have to install `weights` if you want to follow along!):

```{r round_test}
library(weights)

# choose a test value for p - discard leading 0, keep final 0
p1 <- 0.0401
rd(p1, 3) # like round(), I put in the value to round first, then the number of decimal places

# another test value for p - more 0s than three decimal places
p2 <- 0.00001
rd(p2, 3)
```

The first test on 0.0401 came out perfect, but the second test on 0.00001 didn't come out the way I wanted, and got converted to scientific notation instead. So, I will need to tell R that I want a different result when *p* is less than .001. For this, I can use `ifelse()`, like we saw above.

We can put these two things together to make an `ifelse()` command to report *p*-values. The test for `ifelse` is simply whether *p* is greater than or equal to .001. Then, the next two arguments are what to do if that's the case or not. Let's have a look:

```{r}
p1 <- 0.0401
p2 <- 0.00001

ifelse(p1 >= .001, rd(p1, 3), " < .001")
ifelse(p2 >= .001, rd(p1, 3), " < .001")
```

This is just about right. Since the symbol I want to use will change from = (for exact values) to < (for values below .001), I can include the sign in the `yes` argument using the `paste0()` function:

```{r}
p1 <- 0.0401
p2 <- 0.00001

ifelse(p1 >= .001, paste0("= ",rd(p1, 3)), "< .001")
ifelse(p2 >= .001, paste0("= ",rd(p1, 3)), "< .001")
```

That's working great. Now, I could just type out this `ifelse` command every time, replacing `p1` or `p2` with the extracted value of `p.value` from `htest`...but that's a lot to remember. Instead, I can turn this into a simple function that will do it for me.

```{r}
report.p <- function(x){
  ifelse(x >= .001, paste0("= ",rd(p1, 3)), "< .001")
}
```

Now I am creating a new object called `report.p`, which is the name of my new function. The element `function(x)` means that to use this function I have to provide a value `x`. Then, we use curly brackets to contain all of the commands we want to execute when we use the function. Here, we only have the one `ifelse` command we already wrote. The only difference is that we've replaced `p1` or `p2` or any other single object name with `x`. When we use this function, R will take whatever we put into the function and assign it to `x` to be used in the `ifelse` command.

The practical upshot of this is that if you run the code above creating the `report.p` function, you now have a brand new shiny custom function that will report *p* for you. You don't have to know or remember whether *p* is smaller or larger than .001, because it will always report it correctly automatically. This is especially useful in Markdown, where I could write the following, using the test output we created above:

<code>,<pre>There was a significant correlation between the strength of sexual attraction and the strength of romantic attraction, *r*(&#96;r sex_rom_test$parameter&#96) = &#96;r sex_rom_test$estimate %>% round(2)&#96;, *p* &#96;r sex_rom_test$p.value %>% report.p&#96;.</pre></code>

Which should appear in Markdown as: 

There was a significant correlation between the strength of sexual attraction and the strength of romantic attraction, *r*(`r sex_rom_test$parameter`) = `r sex_rom_test$estimate %>% round(2)`, *p* `r sex_rom_test$p.value %>% report.p`.

Shiny, eh?

As a final note, keep in mind that these custom-made functions are not a part of any package. If you want to use them in any other document, you must copy the code that creates the function into each document you want to use it in, typically in the `setup` code chunk. Or, if you make enough of them, you could just make and load your own package!
</div>

\ 

<div class=solText>

\ 

That's all for today. See you soon...

\ 

<font size="+4">**Good job!**</font>

\ 

\ 

\ 


